{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom datasets import Dataset\nfrom transformers import AutoTokenizer, AutoModelForMultipleChoice, TrainingArguments, Trainer\nfrom dataclasses import dataclass\nfrom transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\nfrom typing import Optional, Union\nimport torch\nfrom sklearn.metrics import accuracy_score\nfrom transformers import EarlyStoppingCallback","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load data\ntrain_df = pd.read_csv('/kaggle/input/super-ai-engineer-5-question-and-answer/QA/train.csv')\ntest_df = pd.read_csv('/kaggle/input/super-ai-engineer-5-question-and-answer/QA/test.csv')\nsample_submission_df = pd.read_csv('/kaggle/input/super-ai-engineer-5-question-and-answer/QA/sample_submission.csv')\n\n# Preprocessing\ntrain_df = train_df.dropna()\ntrain_df = train_df.reset_index(drop=True)\n\n# Drop rows where the correct answer is not in ['A', 'B', 'C', 'D']\ndrop_indices = train_df[~train_df['correct'].isin(['A', 'B', 'C', 'D'])].index\ntrain_df = train_df.drop(drop_indices).reset_index(drop=True)\n\n# Split the data into training and validation sets\ntrain_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n\n# Convert to Hugging Face Dataset\ntrain_ds = Dataset.from_pandas(train_df)\nval_ds = Dataset.from_pandas(val_df)\n\n# Load tokenizer\nmodel_dir = 'microsoft/deberta-v3-large'  # Use the suggested high-performance model\ntokenizer = AutoTokenizer.from_pretrained(model_dir)\n\n# Preprocessing function\noptions = 'ABCD'\nindices = list(range(4))\n\noption_to_index = {option: index for option, index in zip(options, indices)}\nindex_to_option = {index: option for option, index in zip(options, indices)}\n\ndef preprocess(example):\n    first_sentence = [example['question']] * 4\n    second_sentence = [example[option] for option in options]\n    tokenized_example = tokenizer(first_sentence, second_sentence, truncation=True)\n    \n    # Add label only if 'correct' column exists\n    if 'correct' in example:\n        tokenized_example['label'] = option_to_index[example['correct']]\n    \n    return tokenized_example\n\n# Tokenize datasets\ntokenized_train_ds = train_ds.map(preprocess, batched=False, remove_columns=['question', 'A', 'B', 'C', 'D', 'correct'])\ntokenized_val_ds = val_ds.map(preprocess, batched=False, remove_columns=['question', 'A', 'B', 'C', 'D', 'correct'])\n\n# Data collator\n@dataclass\nclass DataCollatorForMultipleChoice:\n    tokenizer: PreTrainedTokenizerBase\n    padding: Union[bool, str, PaddingStrategy] = True\n    max_length: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n    \n    def __call__(self, features):\n        # Check if 'label' or 'labels' exists in the features\n        label_name = \"label\" if 'label' in features[0].keys() else 'labels'\n        labels = [feature.pop(label_name) if label_name in feature else None for feature in features]\n        \n        batch_size = len(features)\n        num_choices = len(features[0]['input_ids'])\n        flattened_features = [\n            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n        ]\n        flattened_features = sum(flattened_features, [])\n        \n        batch = self.tokenizer.pad(\n            flattened_features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors='pt',\n        )\n        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n        \n        # Add labels to the batch only if they exist\n        if any(label is not None for label in labels):\n            batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n        \n        return batch\n\n# Load model\nmodel = AutoModelForMultipleChoice.from_pretrained(model_dir)\n\n# Define compute_metrics function\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return {\"eval_accuracy\": accuracy_score(labels, predictions)}\n\n# Training arguments with early stopping\ntraining_args = TrainingArguments(\n    output_dir=model_dir,\n    evaluation_strategy='epoch',\n    save_strategy='epoch',\n    load_best_model_at_end=True,\n    metric_for_best_model='eval_accuracy',  # Must match the key in compute_metrics\n    greater_is_better=True,\n    learning_rate=3e-5,\n    per_device_eval_batch_size=4,\n    per_device_train_batch_size=4,\n    num_train_epochs=4,\n    weight_decay=0.01,\n    report_to='none',\n    save_total_limit=2,\n    logging_dir='./logs',\n    logging_steps=10,\n    logging_strategy='steps',\n    seed=42,\n    fp16=True,\n)\n\n# Trainer with EarlyStoppingCallback and compute_metrics\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train_ds,\n    eval_dataset=tokenized_val_ds,\n    tokenizer=tokenizer,\n    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n    compute_metrics=compute_metrics,  # Add compute_metrics here\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],  # Updated patience to 5\n)\n\n# Train the model\ntrainer.train()\n\n# Predict on validation set\nval_predictions = trainer.predict(tokenized_val_ds)\nval_preds = np.argmax(val_predictions.predictions, axis=1)\nval_true = val_df['correct'].map(option_to_index).tolist()\n\n# Calculate accuracy\nval_accuracy = accuracy_score(val_true, val_preds)\nprint(f'Validation Accuracy: {val_accuracy:.4f}')\n\n# Preprocess test dataset\ntest_ds = Dataset.from_pandas(test_df)\ntokenized_test_ds = test_ds.map(preprocess, batched=False, remove_columns=['id', 'question', 'A', 'B', 'C', 'D'])\n\n# Predict on test set\ntest_predictions = trainer.predict(tokenized_test_ds)\ntest_preds = np.argmax(test_predictions.predictions, axis=1)\ntest_preds = [index_to_option[pred] for pred in test_preds]\n\n# Create submission DataFrame\nsubmission_df = pd.DataFrame({'id': test_df['id'], 'answer': test_preds})\nsubmission_df.to_csv('/kaggle/working/submission_question_answer.csv', index=False)\nsubmission_df.head(3)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}